Of course. Here is the complete, file-by-file implementation of the Go daemon application.

### **Step 1: Project Setup**

First, create the directory structure as planned:

```bash
mkdir -p ddia-quiz-bot/cmd/quiz-daemon
mkdir -p ddia-quiz-bot/internal/{app,cli,config,discovery,models,notifier,parser,presenter,state,store}
mkdir -p ddia-quiz-bot/content/{chapters/ch3-storage,stories}
```

### **Step 2: Go Module Initialization**

In the root `ddia-quiz-bot` directory, initialize the Go module.

```bash
cd ddia-quiz-bot
go mod init github.com/your-username/ddia-quiz-bot
```

Now, get the dependencies we'll need:

```bash
go get gopkg.in/yaml.v3
go get github.com/spf13/cobra
go get github.com/fsnotify/fsnotify
```

---

### **Step 3: The Code (File by File)**

#### **`internal/models/story.go`**

```go
package models

import "time"

// Story represents a single story file from the stories/ directory.
type Story struct {
	// --- File Metadata (not in YAML) ---
	Path     string `yaml:"-"`
	Filename string `yaml:"-"`

	// --- Frontmatter ---
	Title          string   `yaml:"title"`
	Source         string   `yaml:"source"`
	URL            string   `yaml:"url"`
	Date           string   `yaml:"date"` // Keep as string for parsing flexibility
	Author         string   `yaml:"author"`
	Tags           []string `yaml:"tags"`
	RelatesTo      []string `yaml:"relates_to"` // Links to specific Question IDs
	Topics         []string `yaml:"topics"`
	Type           string   `yaml:"type"`
	Difficulty     string   `yaml:"difficulty"`
	BestPairedWith []string `yaml:"best_paired_with"`
	EngagementHook string   `yaml:"engagement_hook"`

	// --- Content (not in YAML) ---
	ContentMarkdown string `yaml:"-"`
}
```

#### **`internal/models/question.go`**

```go
package models

// Question represents a single question file from a chapters/ directory.
type Question struct {
	// --- File Metadata (not in YAML) ---
	Path      string `yaml:"-"`
	ChapterID string `yaml:"-"` // e.g., "ch3-storage"

	// --- Frontmatter ---
	ID             string   `yaml:"id"`
	Day            int      `yaml:"day"`
	Tags           []string `yaml:"tags"`
	RelatedStories []string `yaml:"related_stories"`

	// --- Content (not in YAML) ---
	ContentMarkdown string `yaml:"-"`
	Scenario        string `yaml:"-"`
	QuestionText    string `yaml:"-"`
	Explanation     string `yaml:"-"`
	Hook            string `yaml:"-"`
}
```

#### **`internal/models/schedule.go`**

```go
package models

import "time"

// Schedule represents the structure of schedule.yml.
type Schedule struct {
	Chapters []ChapterSchedule `yaml:"chapters"`
}

type ChapterSchedule struct {
	Chapter   int                `yaml:"chapter"`
	Path      string             `yaml:"path"`
	StartDate string             `yaml:"start_date"`
	Questions []QuestionSchedule `yaml:"questions"`
}

func (cs *ChapterSchedule) GetStartDate() (time.Time, error) {
	return time.Parse("2006-01-02", cs.StartDate)
}

type QuestionSchedule struct {
	Day            int      `yaml:"day"`
	File           string   `yaml:"file"`
	IncludeStories []string `yaml:"include_stories,omitempty"`
	ExcludeStories []string `yaml:"exclude_stories,omitempty"`
}
```

#### **`internal/parser/parser.go`**

```go
package parser

import (
	"bufio"
	"bytes"
	"errors"
	"io/ioutil"
	"regexp"
	"strings"

	"gopkg.in/yaml.v3"
)

var (
	frontmatterDelimiter = []byte("---")
	// Regex to extract specific sections from markdown
	sectionRegex = regexp.MustCompile(`(?s)##\s*(scenario|question|explanation|hook)\n(.*?)(?=\n##|\z)`)
)

// ParseFile reads a byte slice and separates the YAML frontmatter from the markdown body.
func ParseFile(data []byte) (yamlData, markdownData []byte, err error) {
	if !bytes.HasPrefix(data, frontmatterDelimiter) {
		return nil, nil, errors.New("file does not have a YAML frontmatter")
	}

	parts := bytes.SplitN(data, frontmatterDelimiter, 3)
	if len(parts) < 3 {
		return nil, nil, errors.New("invalid frontmatter format")
	}

	return parts[1], bytes.TrimSpace(parts[2]), nil
}

// UnmarshalFrontmatter parses the YAML frontmatter into a given struct.
func UnmarshalFrontmatter(yamlData []byte, v interface{}) error {
	return yaml.Unmarshal(yamlData, v)
}

// ParseQuestionSections extracts specific h2 sections from a question's markdown body.
func ParseQuestionSections(markdownData []byte, q *models.Question) {
	matches := sectionRegex.FindAllSubmatch(markdownData, -1)
	rawContent := string(markdownData)

	for _, match := range matches {
		sectionTitle := strings.ToLower(string(match[1]))
		sectionContent := strings.TrimSpace(string(match[2]))

		switch sectionTitle {
		case "scenario":
			q.Scenario = sectionContent
		case "question":
			q.QuestionText = sectionContent
		case "explanation":
			q.Explanation = sectionContent
		case "hook":
			q.Hook = sectionContent
		}

		// Remove the parsed section from the raw content to isolate the main question title
		rawContent = strings.Replace(rawContent, string(match[0]), "", 1)
	}
	q.ContentMarkdown = strings.TrimSpace(rawContent)
}

// ReadAndParseFile is a helper to read a file and parse it.
func ReadAndParseFile(path string) ([]byte, []byte, error) {
	data, err := ioutil.ReadFile(path)
	if err != nil {
		return nil, nil, err
	}
	return ParseFile(data)
}
```

#### **`internal/config/loader.go`**

```go
package config

import (
	"io/ioutil"
	"path/filepath"

	"gopkg.in/yaml.v3"
)

// LoadSchedule reads and parses the schedule.yml file.
func LoadSchedule(path string) (*models.Schedule, error) {
	data, err := ioutil.ReadFile(path)
	if err != nil {
		return nil, err
	}

	var schedule models.Schedule
	if err := yaml.Unmarshal(data, &schedule); err != nil {
		return nil, err
	}

	return &schedule, nil
}
```

#### **`internal/store/store.go`**

```go
package store

import (
	"os"
	"path/filepath"
	"strings"

	"github.com/your-username/ddia-quiz-bot/internal/parser"
)

// ContentStore acts as an in-memory database for all parsed quiz content.
type ContentStore struct {
	QuestionsByID     map[string]*models.Question
	StoriesByFilename map[string]*models.Story
	AllStories        []*models.Story
}

// NewContentStore creates and populates a store by scanning a content directory.
func NewContentStore(contentDir string) (*ContentStore, error) {
	store := &ContentStore{
		QuestionsByID:     make(map[string]*models.Question),
		StoriesByFilename: make(map[string]*models.Story),
		AllStories:        []*models.Story{},
	}

	if err := store.loadStories(filepath.Join(contentDir, "stories")); err != nil {
		return nil, err
	}

	if err := store.loadChapters(filepath.Join(contentDir, "chapters")); err != nil {
		return nil, err
	}

	return store, nil
}

func (cs *ContentStore) loadStories(storiesDir string) error {
	return filepath.Walk(storiesDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.HasSuffix(info.Name(), ".md") {
			yamlData, mdData, err := parser.ReadAndParseFile(path)
			if err != nil {
				return err // Or log and continue
			}

			var story models.Story
			if err := parser.UnmarshalFrontmatter(yamlData, &story); err != nil {
				return err // Or log and continue
			}

			story.Path = path
			story.Filename = strings.TrimSuffix(info.Name(), ".md")
			story.ContentMarkdown = string(mdData)

			cs.StoriesByFilename[story.Filename] = &story
			cs.AllStories = append(cs.AllStories, &story)
		}
		return nil
	})
}

func (cs *ContentStore) loadChapters(chaptersDir string) error {
	return filepath.Walk(chaptersDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.HasSuffix(info.Name(), ".md") && info.Name() != "_meta.md" {
			yamlData, mdData, err := parser.ReadAndParseFile(path)
			if err != nil {
				return err
			}

			var question models.Question
			if err := parser.UnmarshalFrontmatter(yamlData, &question); err != nil {
				return err
			}

			question.Path = path
			question.ChapterID = filepath.Base(filepath.Dir(path))
			parser.ParseQuestionSections(mdData, &question) // Populate structured fields

			cs.QuestionsByID[question.ID] = &question
		}
		return nil
	})
}
```

#### **`internal/discovery/matcher.go`**

```go
package discovery

import "fmt"

// Matcher finds relationships between stories and questions.
type Matcher struct {
	Store *store.ContentStore
}

// FindStoriesForQuestion implements the two-way linking logic.
func (m *Matcher) FindStoriesForQuestion(
	questionID string,
	scheduleRules *models.QuestionSchedule,
) ([]*models.Story, error) {
	question, exists := m.Store.QuestionsByID[questionID]
	if !exists {
		return nil, fmt.Errorf("question with ID '%s' not found in store", questionID)
	}

	storiesFound := make(map[string]*models.Story)

	// 1. Story -> Question (story's `relates_to` points to this question)
	for _, story := range m.Store.AllStories {
		for _, relatesToID := range story.RelatesTo {
			if relatesToID == questionID {
				storiesFound[story.Filename] = story
			}
		}
	}

	// 2. Question -> Story (question's `related_stories` points to a story)
	for _, storyFilename := range question.RelatedStories {
		if story, ok := m.Store.StoriesByFilename[storyFilename]; ok {
			storiesFound[story.Filename] = story
		}
	}

	// 3. Schedule overrides
	if scheduleRules != nil {
		// Include stories
		for _, storyFilename := range scheduleRules.IncludeStories {
			if story, ok := m.Store.StoriesByFilename[storyFilename]; ok {
				storiesFound[story.Filename] = story
			}
		}
		// Exclude stories
		for _, storyFilename := range scheduleRules.ExcludeStories {
			delete(storiesFound, storyFilename)
		}
	}

	// Convert map to slice
	result := make([]*models.Story, 0, len(storiesFound))
	for _, story := range storiesFound {
		result = append(result, story)
	}
	return result, nil
}
```

#### **`internal/state/manager.go`**

```go
package state

import (
	"encoding/json"
	"io/ioutil"
	"os"
	"sync"
	"time"
)

// Manager handles the persistent state of posted items.
type Manager struct {
	filepath string
	posted   map[string]time.Time // Question ID -> Post Timestamp
	mutex    sync.RWMex
}

// NewManager creates a manager and loads initial state from disk.
func NewManager(filepath string) (*Manager, error) {
	m := &Manager{
		filepath: filepath,
		posted:   make(map[string]time.Time),
	}
	if err := m.Load(); err != nil && !os.IsNotExist(err) {
		return nil, err
	}
	return m, nil
}

// Load reads the state file from disk.
func (m *Manager) Load() error {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	data, err := ioutil.ReadFile(m.filepath)
	if err != nil {
		return err
	}
	return json.Unmarshal(data, &m.posted)
}

// Save writes the current state to disk atomically.
func (m *Manager) Save() error {
	m.mutex.RLock()
	defer m.mutex.RUnlock()

	data, err := json.MarshalIndent(m.posted, "", "  ")
	if err != nil {
		return err
	}
	// Write to a temporary file first, then rename for atomicity
	tempFile := m.filepath + ".tmp"
	if err := ioutil.WriteFile(tempFile, data, 0644); err != nil {
		return err
	}
	return os.Rename(tempFile, m.filepath)
}

// HasPosted checks if a question ID has already been posted.
func (m *Manager) HasPosted(questionID string) bool {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	_, exists := m.posted[questionID]
	return exists
}

// MarkAsPosted records that a question has been posted.
func (m *Manager) MarkAsPosted(questionID string) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	m.posted[questionID] = time.Now().UTC()
}
```

#### **`internal/presenter/presenter.go`**

```go
package presenter

import (
	"bytes"
	"fmt"
	"text/template"
)

// DailyPost is a generic struct containing everything needed for a day's output.
type DailyPost struct {
	Question *models.Question
	Stories  []*models.Story
	Date     time.Time
}

// SocialPresenter formats output for a social media channel.
type SocialPresenter struct{}

const socialTemplate = `ðŸ”¥ DDIA {{.Question.ChapterID}} - Day {{.Question.Day}}

{{.Question.QuestionText}}

---
{{if .Stories}}
ðŸ“– Real-World Example(s):
{{range .Stories}}
ðŸŽ¬ {{.Title}}
{{.EngagementHook}}
Read more: [link to {{.Filename}} story]
{{end}}
#DDIA #RealWorld
{{end}}`

func (p *SocialPresenter) Format(post *DailyPost) (string, error) {
	tmpl, err := template.New("social").Parse(socialTemplate)
	if err != nil {
		return "", err
	}

	var buf bytes.Buffer
	if err := tmpl.Execute(&buf, post); err != nil {
		return "", err
	}

	return buf.String(), nil
}
```

#### **`internal/notifier/notifier.go`**

```go
package notifier

import "log"

// Notifier is the interface for sending a formatted post to a platform.
type Notifier interface {
	Notify(content string) error
}

// LogNotifier is a simple implementation that prints to a logger.
type LogNotifier struct {
	Logger *log.Logger
}

func (n *LogNotifier) Notify(content string) error {
	n.Logger.Println("--- NEW POST ---")
	n.Logger.Println(content)
	n.Logger.Println("--- END POST ---")
	return nil
}
```

#### **`internal/app/daemon.go`** (The Orchestrator)

```go
package app

import (
	"fmt"
	"log"
	"os"
	"os/signal"
	"path/filepath"
	"sync"
	"syscall"
	"time"

	"github.com/fsnotify/fsnotify"

	"github.com/your-username/ddia-quiz-bot/internal/config"
	"github.com/your-username/ddia-quiz-bot/internal/discovery"
	"github.com/your-username/ddia-quiz-bot/internal/notifier"
	"github.com/your-username/ddia-quiz-bot/internal/presenter"
	"github.com/your-username/ddia-quiz-bot/internal/state"
	"github.com/your-username/ddia-quiz-bot/internal/store"
)

const reloadDebounceDuration = 2 * time.Second

type Daemon struct {
	contentPath    string
	logger         *log.Logger
	notifiers      []notifier.Notifier
	state          *state.Manager
	presenter      *presenter.SocialPresenter
	reloadTimer    *time.Timer
	reloadTimerMux sync.Mutex

	// These are protected by the mutex
	store    *store.ContentStore
	schedule *models.Schedule
	mutex    sync.RWMutex
}

// NewDaemon initializes the application.
func NewDaemon(contentPath string, logger *log.Logger, notifiers []notifier.Notifier, stateMgr *state.Manager) *Daemon {
	return &Daemon{
		contentPath: contentPath,
		logger:      logger,
		notifiers:   notifiers,
		state:       stateMgr,
		presenter:   &presenter.SocialPresenter{},
	}
}

// Run starts all long-running processes.
func (d *Daemon) Run() error {
	d.logger.Println("Starting DDIA Quiz Daemon...")

	// 1. Initial Load
	if err := d.Reload(); err != nil {
		return fmt.Errorf("initial load failed: %w", err)
	}
	d.logger.Println("Initial content loaded successfully.")

	// 2. Start Filesystem Watcher
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return fmt.Errorf("failed to create file watcher: %w", err)
	}
	defer watcher.Close()

	if err := filepath.Walk(d.contentPath, func(path string, info os.FileInfo, err error) error {
		if info.IsDir() {
			return watcher.Add(path)
		}
		return nil
	}); err != nil {
		return fmt.Errorf("failed to add paths to watcher: %w", err)
	}

	// 3. Start Scheduler Ticker and Signal Handler
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()
	signalChan := make(chan os.Signal, 1)
	signal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM)

	d.logger.Println("Daemon is running. Watching for file changes and scheduled posts.")

	// 4. Main Event Loop
	for {
		select {
		case <-ticker.C:
			d.checkForScheduledPosts()
		case event := <-watcher.Events:
			d.handleFileChange(event)
		case err := <-watcher.Errors:
			d.logger.Printf("ERROR: Watcher error: %v", err)
		case <-signalChan:
			d.logger.Println("Shutdown signal received. Saving state and exiting.")
			if err := d.state.Save(); err != nil {
				d.logger.Printf("ERROR: Failed to save state on shutdown: %v", err)
			}
			return nil
		}
	}
}

// handleFileChange debounces reload events.
func (d *Daemon) handleFileChange(event fsnotify.Event) {
	if event.Op&fsnotify.Write == fsnotify.Write || event.Op&fsnotify.Create == fsnotify.Create {
		d.reloadTimerMux.Lock()
		// If a timer is already running, reset it
		if d.reloadTimer != nil {
			d.reloadTimer.Stop()
		}
		// Set a new timer
		d.reloadTimer = time.AfterFunc(reloadDebounceDuration, func() {
			if err := d.Reload(); err != nil {
				d.logger.Printf("ERROR: Automatic reload failed: %v", err)
			}
		})
		d.reloadTimerMux.Unlock()
	}
}

// Reload attempts to load all config and content from disk.
func (d *Daemon) Reload() error {
	d.logger.Println("Change detected. Attempting to reload schedule and content...")

	newSchedule, err := config.LoadSchedule(filepath.Join(d.contentPath, "schedule.yml"))
	if err != nil {
		return fmt.Errorf("failed to parse schedule.yml: %w", err)
	}

	newStore, err := store.NewContentStore(d.contentPath)
	if err != nil {
		return fmt.Errorf("failed to load content store: %w", err)
	}

	// Validation (optional but recommended)
	// You could add a `Validate(schedule, store)` function here

	d.mutex.Lock()
	d.schedule = newSchedule
	d.store = newStore
	d.mutex.Unlock()

	d.logger.Println("Reload successful. Now running with updated configuration.")
	return nil
}

func (d *Daemon) checkForScheduledPosts() {
	d.mutex.RLock()
	schedule := d.schedule
	store := d.store
	d.mutex.RUnlock()

	if schedule == nil || store == nil {
		return // Not loaded yet
	}

	matcher := &discovery.Matcher{Store: store}
	now := time.Now()
	needsSave := false

	for _, chap := range schedule.Chapters {
		startDate, err := chap.GetStartDate()
		if err != nil {
			d.logger.Printf("WARN: Invalid start_date for chapter %d: %v", chap.Chapter, err)
			continue
		}

		for _, qSched := range chap.Questions {
			question, exists := store.QuestionsByID[qSched.File]
			if !exists {
				// The question file might have a different ID in its frontmatter, let's find it
				var foundQ *models.Question
				for _, q := range store.QuestionsByID {
					if filepath.Base(q.Path) == qSched.File {
						foundQ = q
						break
					}
				}
				if foundQ == nil {
					d.logger.Printf("WARN: Question file '%s' from schedule not found in store.", qSched.File)
					continue
				}
				question = foundQ
			}

			if d.state.HasPosted(question.ID) {
				continue
			}

			// Post time is start date + (day-1) days, at a specific time (e.g., 10:00 UTC)
			postDate := startDate.AddDate(0, 0, qSched.Day-1)
			postTime := time.Date(postDate.Year(), postDate.Month(), postDate.Day(), 10, 0, 0, time.UTC)

			if now.After(postTime) {
				d.logger.Printf("Found pending post: %s", question.ID)

				stories, err := matcher.FindStoriesForQuestion(question.ID, &qSched)
				if err != nil {
					d.logger.Printf("ERROR: Could not find stories for %s: %v", question.ID, err)
					continue
				}

				dailyPost := &presenter.DailyPost{
					Question: question,
					Stories:  stories,
					Date:     now,
				}

				content, err := d.presenter.Format(dailyPost)
				if err != nil {
					d.logger.Printf("ERROR: Could not format post for %s: %v", question.ID, err)
					continue
				}

				// Send to all notifiers
				for _, n := range d.notifiers {
					if err := n.Notify(content); err != nil {
						d.logger.Printf("ERROR: Notifier failed for %s: %v", question.ID, err)
						// Decide on retry logic here if needed
					}
				}

				d.state.MarkAsPosted(question.ID)
				needsSave = true
			}
		}
	}

	if needsSave {
		if err := d.state.Save(); err != nil {
			d.logger.Printf("ERROR: Failed to save state after posting: %v", err)
		}
	}
}
```

#### **`cmd/quiz-daemon/main.go`** (The Entrypoint)

```go
package main

import (
	"flag"
	"log"
	"os"
	"path/filepath"

	"github.com/your-username/ddia-quiz-bot/internal/app"
	"github.com/your-username/ddia-quiz-bot/internal/notifier"
	"github.com/your-username/ddia-quiz-bot/internal/state"
)

func main() {
	contentPath := flag.String("path", "./content", "Path to the content directory")
	flag.Parse()

	logger := log.New(os.Stdout, "QUIZ-DAEMON: ", log.LstdFlags)

	// --- Setup Dependencies ---

	// 1. State Manager
	statePath := filepath.Join(*contentPath, "post_history.json")
	stateMgr, err := state.NewManager(statePath)
	if err != nil {
		logger.Fatalf("Failed to initialize state manager: %v", err)
	}

	// 2. Notifiers (add more here in the future)
	logNotifier := &notifier.LogNotifier{Logger: logger}
	allNotifiers := []notifier.Notifier{logNotifier}

	// 3. Create the Daemon
	daemon := app.NewDaemon(*contentPath, logger, allNotifiers, stateMgr)

	// --- Run the Daemon ---
	if err := daemon.Run(); err != nil {
		logger.Fatalf("Daemon exited with error: %v", err)
	}
	logger.Println("Daemon shut down gracefully.")
}
```

---

### **Step 4: Sample Content Files**

Place these files in the `content/` directory.

#### **`content/schedule.yml`**

```yaml
chapters:
  - chapter: 3
    path: "chapters/ch3-storage"
    start_date: "2025-10-06" # Use a past date to test immediate posting
    questions:
      - day: 1
        file: "01-kv-basics.md"
      - day: 2
        file: "02-compaction.md"
        include_stories:
          - netflix-cassandra
```

#### **`content/stories/netflix-cassandra.md`**

```markdown
---
title: How Netflix Handles 1 Trillion Events/Day with Cassandra
source: Netflix Tech Blog
url: https://netflixtechblog.com/...
date: 2024-09-15
author: Netflix Engineering
tags: [sstables, compaction, distributed-systems, scale]
relates_to:
  - ch3_compaction_02
engagement_hook: Netflix found that tuning compaction saved them $2M/year in infrastructure!
---
# How Netflix Handles 1 Trillion Events/Day with Cassandra

This is the main content of the story.
```

#### **`content/chapters/ch3-storage/02-compaction.md`**

```markdown
---
id: ch3_compaction_02
day: 2
tags: [compaction, storage, optimization]
related_stories: []
---

# Compaction Strategy

## question
Which statement is TRUE about handling duplicate keys during compaction?

## options
- A) Keep all duplicates to maintain complete history
- B) Keep only the most recent value

## answer
B

## explanation
Compaction keeps only the latest value per key.
```

---

### **Step 5: How to Run**

1.  Make sure all the files are created in the correct directories.
2.  Open your terminal in the `ddia-quiz-bot` root directory.
3.  Run the daemon:
    ```bash
    go run ./cmd/quiz-daemon/main.go --path ./content
    ```

**What you will see:**

1.  The daemon will start and log that it has loaded the initial content.
2.  Because the `start_date` in `schedule.yml` is in the past, it will almost immediately find the pending post for day 2 (`ch3_compaction_02`).
3.  It will format a post including the question and the Netflix story, and print it to your console (because we are using the `LogNotifier`).
4.  It will create a `content/post_history.json` file to remember that it sent this post.
5.  The daemon will then sit idle.

**To test the live reload:**

1.  While the daemon is running, open `content/schedule.yml` in a text editor.
2.  Change the `start_date` to a future date and save the file.
3.  You will see a log message in the daemon's terminal indicating that it has detected a change and successfully reloaded the configuration.